{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72138fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "# suppress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f46029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/liamsweeney/dat-11-15/ClassMaterial/Unit3/data/ks2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4c16be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09 00:00:00</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01 00:00:00</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26 00:00:00</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16 00:00:00</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29 00:00:00</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370449</th>\n",
       "      <td>999976400</td>\n",
       "      <td>ChknTruk Nationwide Charity Drive 2014 (Canceled)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-10-17 00:00:00</td>\n",
       "      <td>2014-09-17 02:35:30</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>50000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370450</th>\n",
       "      <td>999977640</td>\n",
       "      <td>The Tribe</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2011-07-19 00:00:00</td>\n",
       "      <td>2011-06-22 03:35:14</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370451</th>\n",
       "      <td>999986353</td>\n",
       "      <td>Walls of Remedy- New lesbian Romantic Comedy f...</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2010-08-16 00:00:00</td>\n",
       "      <td>2010-07-01 19:40:30</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>15000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370452</th>\n",
       "      <td>999987933</td>\n",
       "      <td>BioDefense Education Kit</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-02-13 00:00:00</td>\n",
       "      <td>2016-01-13 18:13:53</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>15000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370453</th>\n",
       "      <td>999988282</td>\n",
       "      <td>Nou Renmen Ayiti!  We Love Haiti!</td>\n",
       "      <td>Performance Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>USD</td>\n",
       "      <td>2011-08-16 00:00:00</td>\n",
       "      <td>2011-07-19 09:07:47</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                               name  \\\n",
       "0       1000002330                    The Songs of Adelaide & Abullah   \n",
       "1       1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2       1000004038                                     Where is Hank?   \n",
       "3       1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4       1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "...            ...                                                ...   \n",
       "370449   999976400  ChknTruk Nationwide Charity Drive 2014 (Canceled)   \n",
       "370450   999977640                                          The Tribe   \n",
       "370451   999986353  Walls of Remedy- New lesbian Romantic Comedy f...   \n",
       "370452   999987933                           BioDefense Education Kit   \n",
       "370453   999988282                  Nou Renmen Ayiti!  We Love Haiti!   \n",
       "\n",
       "               category main_category currency             deadline  \\\n",
       "0                Poetry    Publishing      GBP  2015-10-09 00:00:00   \n",
       "1        Narrative Film  Film & Video      USD  2017-11-01 00:00:00   \n",
       "2        Narrative Film  Film & Video      USD  2013-02-26 00:00:00   \n",
       "3                 Music         Music      USD  2012-04-16 00:00:00   \n",
       "4          Film & Video  Film & Video      USD  2015-08-29 00:00:00   \n",
       "...                 ...           ...      ...                  ...   \n",
       "370449      Documentary  Film & Video      USD  2014-10-17 00:00:00   \n",
       "370450   Narrative Film  Film & Video      USD  2011-07-19 00:00:00   \n",
       "370451   Narrative Film  Film & Video      USD  2010-08-16 00:00:00   \n",
       "370452       Technology    Technology      USD  2016-02-13 00:00:00   \n",
       "370453  Performance Art           Art      USD  2011-08-16 00:00:00   \n",
       "\n",
       "                   launched  state country      goal  \n",
       "0       2015-08-11 12:12:28      0      GB   1533.95  \n",
       "1       2017-09-02 04:43:57      0      US  30000.00  \n",
       "2       2013-01-12 00:20:50      0      US  45000.00  \n",
       "3       2012-03-17 03:24:11      0      US   5000.00  \n",
       "4       2015-07-04 08:35:03      0      US  19500.00  \n",
       "...                     ...    ...     ...       ...  \n",
       "370449  2014-09-17 02:35:30      0      US  50000.00  \n",
       "370450  2011-06-22 03:35:14      0      US   1500.00  \n",
       "370451  2010-07-01 19:40:30      0      US  15000.00  \n",
       "370452  2016-01-13 18:13:53      0      US  15000.00  \n",
       "370453  2011-07-19 09:07:47      0      US   2000.00  \n",
       "\n",
       "[370454 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13beff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to aid in the process\n",
    "def split_data(df, split_frac=0.2, random_state=42):\n",
    "    df = df.drop(['deadline', 'launched'], axis = 1)\n",
    "    X  = df.drop('state', axis=1)\n",
    "    y  = df['state']\n",
    "    # notice the use of 'stratify' -- makes sure y values are in equal proportions in train + test\n",
    "    return train_test_split(X, y, test_size = split_frac, stratify = y, random_state = random_state)\n",
    "\n",
    "# helper function to pull out feature importances_\n",
    "def get_feature_importances(pipe, X_train, onehot=False):\n",
    "    if onehot:\n",
    "        X_train = pipe[0].transform(X_train)\n",
    "        X_train = pipe[1].transform(X_train)\n",
    "    return pd.DataFrame({\n",
    "        'Col': X_train.columns,\n",
    "        'Importance': pipe[-1].feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "# a variation of what we did previously -- gives us option of getting training / validation / test scores\n",
    "# in a single function\n",
    "def get_model_scores(mod, X_train, y_train, X_test, y_test, val_score = True, test_score=False):\n",
    "    if val_score:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size = 0.2, \n",
    "                                                          stratify = y_train, \n",
    "                                                          random_state= 42)\n",
    " \n",
    "    mod.fit(X_train, y_train)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['train_score'] = mod.score(X_train, y_train)\n",
    "    if val_score:\n",
    "        results['val_score'] = mod.score(X_val, y_val)\n",
    "        \n",
    "    if test_score:\n",
    "        results['test_score'] = mod.score(X_test, y_test)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a6e33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(pipe, X_train, onehot=False):\n",
    "    if onehot:\n",
    "        # this section is based on the assumption that we are using a OneHotEncoder + An additional one for name\n",
    "        X_train = pipe[0].transform(X_train)\n",
    "        X_train = pipe[1].transform(X_train)\n",
    "    return pd.DataFrame({\n",
    "        'Col': X_train.columns,\n",
    "        'Importance': pipe[-1].feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7beb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# create pipe and get model score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd606bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "te   = ce.TargetEncoder(min_samples_leaf = 30)\n",
    "# setting eval_metric here to avoid a warning message -- does not really change anything though\n",
    "mod  = XGBClassifier(eval_metric = 'logloss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "416865a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(te, mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db688ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_model_scores(pipe, X_train, y_train, X_test, y_test, test_score = True)\n",
    "\n",
    "# initial scores are closely aligned, will leave test set alone for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16aae348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.6991522206756928,\n",
       " 'val_score': 0.6874799655829804,\n",
       " 'test_score': 0.6884776828494689}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d454bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>0.523398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>goal</td>\n",
       "      <td>0.205392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country</td>\n",
       "      <td>0.103629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main_category</td>\n",
       "      <td>0.072589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currency</td>\n",
       "      <td>0.060460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>0.034531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Col  Importance\n",
       "2       category    0.523398\n",
       "6           goal    0.205392\n",
       "5        country    0.103629\n",
       "3  main_category    0.072589\n",
       "4       currency    0.060460\n",
       "0             ID    0.034531\n",
       "1           name    0.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = get_feature_importances(pipe, X_train)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "140824ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.6977772154034333, 'val_score': 0.6883572621598367}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = ce.OneHotEncoder(cols = ['category', 'country', 'currency'], use_cat_names = True)\n",
    "te  = ce.TargetEncoder()\n",
    "\n",
    "pipe = make_pipeline(ohe, te, mod)\n",
    "\n",
    "scores = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# initial scores are closely aligned, will leave test set alone for now\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1cb87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>category_Hip-Hop</td>\n",
       "      <td>0.064007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>main_category</td>\n",
       "      <td>0.050888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>category_Tabletop Games</td>\n",
       "      <td>0.041593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>category_Shorts</td>\n",
       "      <td>0.034393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>country_US</td>\n",
       "      <td>0.029721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>category_Cookbooks</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>category_Gaming Hardware</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>currency_JPY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>category_Rock</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>category_Calendars</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Col  Importance\n",
       "58           category_Hip-Hop    0.064007\n",
       "161             main_category    0.050888\n",
       "28    category_Tabletop Games    0.041593\n",
       "8             category_Shorts    0.034393\n",
       "176                country_US    0.029721\n",
       "..                        ...         ...\n",
       "77         category_Cookbooks    0.000000\n",
       "61   category_Gaming Hardware    0.000000\n",
       "175              currency_JPY    0.000000\n",
       "47              category_Rock    0.000000\n",
       "100        category_Calendars    0.000000\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = get_feature_importances(pipe, X_train, onehot=True)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8c9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "df['launched'] = pd.to_datetime(df['launched'])\n",
    "\n",
    "# let 'er rip\n",
    "df['deadline_days'] = df['deadline'].dt.day\n",
    "df['deadline_mo']   = df['deadline'].dt.month\n",
    "df['deadline_year'] = df['deadline'].dt.year\n",
    "df['time']          = (df['deadline'] - df['deadline'].min()).dt.days\n",
    "df['duration']      = (df['deadline'] - df['launched'].min()).dt.days\n",
    "df['deadline_dow']  = df['deadline'].dt.dayofweek\n",
    "df['deadline_week'] = df['deadline'].dt.week\n",
    "\n",
    "# let 'er rip\n",
    "df['launched_days'] = df['launched'].dt.day\n",
    "df['launched_mo']   = df['launched'].dt.month\n",
    "df['launched_year'] = df['launched'].dt.year\n",
    "df['launched_dow']  = df['launched'].dt.dayofweek\n",
    "df['launched_week'] = df['launched'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56d66e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ry/lx4fw4hj4c58xy781z3_7cbm0000gn/T/ipykernel_47633/690677767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# very modest difference -- will keep for now, even though it seems to have a small difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ry/lx4fw4hj4c58xy781z3_7cbm0000gn/T/ipykernel_47633/184424680.py\u001b[0m in \u001b[0;36mget_model_scores\u001b[0;34m(mod, X_train, y_train, X_test, y_test, val_score, test_score)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                           random_state= 42)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# re split and score\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# very modest difference -- will keep for now, even though it seems to have a small difference\n",
    "scores = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948187e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>category_Hip-Hop</td>\n",
       "      <td>0.067006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>main_category</td>\n",
       "      <td>0.053235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>category_Tabletop Games</td>\n",
       "      <td>0.042709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>category_Shorts</td>\n",
       "      <td>0.028079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>category_Apps</td>\n",
       "      <td>0.026539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>currency_HKD</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>category_Journalism</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>currency_JPY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>category_Punk</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>category_Architecture</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Col  Importance\n",
       "58          category_Hip-Hop    0.067006\n",
       "161            main_category    0.053235\n",
       "28   category_Tabletop Games    0.042709\n",
       "8            category_Shorts    0.028079\n",
       "14             category_Apps    0.026539\n",
       "..                       ...         ...\n",
       "173             currency_HKD    0.000000\n",
       "57       category_Journalism    0.000000\n",
       "175             currency_JPY    0.000000\n",
       "50             category_Punk    0.000000\n",
       "71     category_Architecture    0.000000\n",
       "\n",
       "[212 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = get_feature_importances(pipe, X_train, onehot=True)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1863f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>goal</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>deadline_dow</th>\n",
       "      <th>deadline_week</th>\n",
       "      <th>launched_days</th>\n",
       "      <th>launched_mo</th>\n",
       "      <th>launched_year</th>\n",
       "      <th>launched_dow</th>\n",
       "      <th>launched_week</th>\n",
       "      <th>cat_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>...</td>\n",
       "      <td>2350</td>\n",
       "      <td>16716</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.286323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1001028167</td>\n",
       "      <td>Steel Cathedrals- Short poems for the digital ...</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2013-07-28</td>\n",
       "      <td>2013-06-28 23:17:04</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>6060.97</td>\n",
       "      <td>...</td>\n",
       "      <td>1547</td>\n",
       "      <td>15913</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1.131324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1001468086</td>\n",
       "      <td>Bass River Press</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-04-05</td>\n",
       "      <td>2015-03-06 19:58:58</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2163</td>\n",
       "      <td>16529</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.373315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1001991458</td>\n",
       "      <td>Poems For Apostates &amp; tales of a young Sciento...</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-05-31</td>\n",
       "      <td>2014-05-01 17:47:49</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1854</td>\n",
       "      <td>16220</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.866573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1002519316</td>\n",
       "      <td>Your poem, by me.</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>CAD</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>2015-10-01 20:00:32</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>757.52</td>\n",
       "      <td>...</td>\n",
       "      <td>2372</td>\n",
       "      <td>16738</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.141397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               name category  \\\n",
       "0    1000002330                    The Songs of Adelaide & Abullah   Poetry   \n",
       "232  1001028167  Steel Cathedrals- Short poems for the digital ...   Poetry   \n",
       "318  1001468086                                   Bass River Press   Poetry   \n",
       "414  1001991458  Poems For Apostates & tales of a young Sciento...   Poetry   \n",
       "517  1002519316                                  Your poem, by me.   Poetry   \n",
       "\n",
       "    main_category currency   deadline            launched  state country  \\\n",
       "0      Publishing      GBP 2015-10-09 2015-08-11 12:12:28      0      GB   \n",
       "232    Publishing      GBP 2013-07-28 2013-06-28 23:17:04      0      GB   \n",
       "318    Publishing      USD 2015-04-05 2015-03-06 19:58:58      0      US   \n",
       "414    Publishing      USD 2014-05-31 2014-05-01 17:47:49      0      US   \n",
       "517    Publishing      CAD 2015-10-31 2015-10-01 20:00:32      0      CA   \n",
       "\n",
       "         goal  ...  time  duration  deadline_dow  deadline_week  \\\n",
       "0     1533.95  ...  2350     16716             4             41   \n",
       "232   6060.97  ...  1547     15913             6             30   \n",
       "318   2000.00  ...  2163     16529             6             14   \n",
       "414  10000.00  ...  1854     16220             5             22   \n",
       "517    757.52  ...  2372     16738             5             44   \n",
       "\n",
       "     launched_days  launched_mo  launched_year  launched_dow  launched_week  \\\n",
       "0               11            8           2015             1             33   \n",
       "232             28            6           2013             4             26   \n",
       "318              6            3           2015             4             10   \n",
       "414              1            5           2014             3             18   \n",
       "517              1           10           2015             3             40   \n",
       "\n",
       "      cat_avg  \n",
       "0    0.286323  \n",
       "232  1.131324  \n",
       "318  0.373315  \n",
       "414  1.866573  \n",
       "517  0.141397  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category averages\n",
    "train_idx = X_train.index\n",
    "\n",
    "# averages by category\n",
    "# do you know why we're only grabbing the indices in the training set?\n",
    "cat_avgs      = df.iloc[train_idx].groupby('category')['goal'].mean().to_frame().rename({'goal': 'cat_avg'}, axis = 1)\n",
    "df            = df.merge(cat_avgs, left_on = 'category', right_index = True )\n",
    "df['cat_avg'] = df['goal'] / df['cat_avg']\n",
    "\n",
    "# and now our new data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf8e8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.7189349736527906, 'val_score': 0.699022900248072}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# averages by category / country\n",
    "country_avgs      = df.iloc[train_idx].groupby(['country', 'category'])['goal'].mean().to_frame().rename({'goal': 'country_avg'}, axis = 1)\n",
    "df                = df.merge(country_avgs, left_on = ['country', 'category'], right_index = True)\n",
    "df['country_avg'] = df['goal'] / df['country_avg']\n",
    "\n",
    "# re - split & score\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "scores                           = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# and scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90826245",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So far it seems that the additional info that we've created does not add a lot of additional predictive value. However, before ditching it, we'll keep all of it during parameter tuning. The idea is that it's possible certain types of interactions and features might be picked up during later boosting rounds that we cannot see now.\n",
    "\n",
    "We'll look at parameter tuning using the way we've always done it, as well as a more convenient wrapper called GridSearch, which we'll use in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7eb3a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new training loop for rounds: 100, depth: 3, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 100, depth: 3, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 100, depth: 4, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 100, depth: 4, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 200, depth: 3, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 200, depth: 3, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 200, depth: 4, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 200, depth: 4, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 300, depth: 3, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 300, depth: 3, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 300, depth: 4, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 300, depth: 4, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 400, depth: 3, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 400, depth: 3, sampling rate: 0.6\n",
      "Fitting new training loop for rounds: 400, depth: 4, sampling rate: 0.8\n",
      "Fitting new training loop for rounds: 400, depth: 4, sampling rate: 0.6\n"
     ]
    }
   ],
   "source": [
    "# parameter search\n",
    "estimators = [100, 200, 300, 400]\n",
    "max_depth  = [3, 4]\n",
    "sub_sample = [0.8, 0.6] # this is the amount of samples to randomly sample in each round\n",
    "cv_scores  = []\n",
    "\n",
    "# do a training loop\n",
    "for estimator in estimators:\n",
    "    for depth in max_depth:\n",
    "        for sample in sub_sample:\n",
    "            print(f\"Fitting new training loop for rounds: {estimator}, depth: {depth}, sampling rate: {sample}\")\n",
    "            pipe[-1].set_params(n_estimators = estimator, max_depth = depth, subsample = sample)\n",
    "            scores = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "            cv_scores.append((scores['train_score'], scores['val_score'], estimator, depth, sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6147ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we'll now go ahead and find the best parameter values\n",
    "max(cv_scores, \n",
    "    key = lambda x: x[1]) # this is to grab the second item in each tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "pipe[-1].set_params(n_estimators = 400, max_depth = 4, subsample = 0.8)\n",
    "\n",
    "# and finally get our test score\n",
    "scores = get_model_scores(pipe, X_train, y_train, X_test, y_test, val_score = False, test_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb38c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3411d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A couple of points to note here is that our best performing model is also our most complicated, suggesting that we probably have more parameter space to explore in order to maximize performance.\n",
    "\n",
    "It's also true that the spread of values does not seem to be that large, so there's a good chance increasing the size of the model will only bring modest improvements.\n",
    "\n",
    "For now, let's stop and continue on with our test set and PDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "pipe[-1].set_params(n_estimators = 400, max_depth = 4, subsample = 0.8)\n",
    "\n",
    "# and finally get our test score\n",
    "scores = get_model_scores(pipe, X_train, y_train, X_test, y_test, val_score = False, test_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4104e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe86ef2",
   "metadata": {},
   "source": [
    "We can see we got pretty good alignment between training and test scores, suggesting that our validation technique was sound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8453c",
   "metadata": {},
   "source": [
    "We'll now go ahead and look at a simplified way or searching parameters. It fundamentally goes the same thing, but allows you to load in all of the parameters at once without having to go through a complicated loop. It's known as GridSearch: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [100, 200, 300, 400],\n",
    "    'xgbclassifier__max_depth': [3, 4, 5],\n",
    "    'xgbclassifier__max_features': [0.6, 0.8, 1],\n",
    "    'xgbclassifier__subsample': [0.6, 0.8, 0.1]\n",
    "}\n",
    "\n",
    "# we'll apply this option for faster fitting -- a nice feature of xgboost\n",
    "pipe[-1].set_params(tree_method = 'hist')\n",
    "\n",
    "# import a splitter - way to automatically split your data for you\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = kfold, verbose = 1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aada898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give us the best results from the search\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bf442",
   "metadata": {},
   "source": [
    "\n",
    "Partial Dependence\n",
    "\n",
    "With our modeling behind us, we'll now go ahead and pull some PDP charts to see what types of patterns were found inside of our final fitted model. Since category and goal were two important features, we'll look at those two.\n",
    "Your Turn:\n",
    "\n",
    "Now that we've finished with this, try and create PDP plots to answer the following questions:\n",
    "\n",
    "    what is the overall relationship between fundraising amount and your chance of completing a successful campaign?\n",
    "    what campaigns give you the highest probability of successfully completing a campaign? The lowest?\n",
    "    if you have any ambitions for running a campaign, how would the intersection of your campaign category and your desired fundraising amount interact?\n",
    "\n",
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "# go ahead and transform X_train to prep it for PDPBox\n",
    "# the model is already fitted so we don't have to worry about doing that\n",
    "X_train = pipe[0].transform(X_train)\n",
    "X_train = pipe[1].transform(X_train)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "<ipython-input-62-14bfb36aaf96> in <module>\n",
    "----> 1 from pdpbox import pdp, info_plots\n",
    "      2 \n",
    "      3 # go ahead and transform X_train to prep it for PDPBox\n",
    "      4 # the model is already fitted so we don't have to worry about doing that\n",
    "      5 X_train = pipe[0].transform(X_train)\n",
    "\n",
    "ModuleNotFoundError: No module named 'pdpbox'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c6e8e",
   "metadata": {},
   "source": [
    "\n",
    "Your Turn:\n",
    "\n",
    "Now that we've finished with this, try and create PDP plots to answer the following questions:\n",
    "\n",
    "    what is the overall relationship between fundraising amount and your chance of completing a successful campaign?\n",
    "    what campaigns give you the highest probability of successfully completing a campaign? The lowest?\n",
    "    if you have any ambitions for running a campaign, how would the intersection of your campaign category and your desired fundraising amount interact?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "# go ahead and transform X_train to prep it for PDPBox\n",
    "# the model is already fitted so we don't have to worry about doing that\n",
    "X_train = pipe[0].transform(X_train)\n",
    "X_train = pipe[1].transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was the additive impact of different values of goal?  What was its marginal impact?\n",
    "pdp_day_of_week = pdp.pdp_isolate(\n",
    "    model=pipe[-1], \n",
    "    dataset=X_train[X_train['goal'] < X_train['goal'].quantile(.95)], # filtering out unusually large values\n",
    "    model_features=X_train.columns.tolist(), \n",
    "    feature='goal',\n",
    ")\n",
    "\n",
    "fig, axes = pdp.pdp_plot(pdp_day_of_week, 'Fundraising Amount', plot_lines=True, frac_to_plot=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64553248",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in X_train.columns if 'category' in col and col != 'main_category']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_cat = pdp.pdp_isolate(\n",
    "    # dataset -- create the final transformation of our data\n",
    "    model= pipe[-1], dataset=X_train, model_features=X_train.columns.tolist(), \n",
    "    # this is the list of all the columns for the genre feature\n",
    "    feature=cat_cols\n",
    ")\n",
    "\n",
    "fig, axes = pdp.pdp_plot(pdp_cat, 'Category', plot_lines=True, frac_to_plot=100)\n",
    "# this code is just for formatting -- getting the labels to format correctly\n",
    "xtick_labels = [cat.split('_')[1] for cat in cat_cols]\n",
    "axes['pdp_ax'].set_xticklabels(xtick_labels, rotation='vertical');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
